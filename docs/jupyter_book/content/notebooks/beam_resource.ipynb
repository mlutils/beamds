{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e79b4a8-f4c0-4cf3-9d41-c8c90b9170d7",
   "metadata": {},
   "source": [
    "%load_ext beam_setup"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "02235cb7-0887-4e4b-9da9-8aaef2f9eb95",
   "metadata": {},
   "source": [
    "# Use resource to access files and folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d81dd-7fc3-4397-9cd7-d23b41dbe915",
   "metadata": {},
   "source": [
    "A resource can be a file or folder path on: (1) local filesystem, s3 and s3 compatible filesystem, hdfs and sftp connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1460cba8-550d-4371-b05a-5588182ecc11",
   "metadata": {},
   "source": [
    "path = resource('/tmp/path/to/folder')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dfe37106-f71f-4f66-a74c-ff96cd5160d1",
   "metadata": {},
   "source": [
    "The path resource follows the pathlib api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036508ef-073e-4ba4-b7d3-a0805e2e4573",
   "metadata": {},
   "source": [
    "path.mkdir()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5407742-e955-48f5-9d2c-a2be1963e34a",
   "metadata": {},
   "source": [
    "file_path = path.joinpath('a.pt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d97785ac-80b5-44cf-886f-350f0f9ec5cf",
   "metadata": {},
   "source": [
    "but it also supports read and write operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "888fd578-6e87-47b7-afe1-9927ddb13861",
   "metadata": {},
   "source": [
    "file_path.write(torch.randn(4))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36c6b06c-d014-4741-b16c-163e3a3895ae",
   "metadata": {},
   "source": [
    "print(file_path.read())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "09c648c4-b2a8-44cd-aa7b-3bff56ab5111",
   "metadata": {},
   "source": [
    "it supports many file types including: torch (.pt), pickle (.pkl), feather (.fea), parquet (.parquet) and many more (see beam.path.core.PureBeamPath read and write operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196ac82a-2b8a-4078-9d28-eae972e0753e",
   "metadata": {},
   "source": [
    "we can also specify how we would like to store the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ae459b-4538-4221-a103-82f9de8a6675",
   "metadata": {},
   "source": [
    "path.joinpath('some_name_with_no_extention').write(np.random.randn(4), ext='.pkl')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5669375-50c9-44d3-916a-9d6f590ec9a0",
   "metadata": {},
   "source": [
    "path.joinpath('some_name_with_no_extention').read(ext='.pkl')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d8895445-a25b-42ff-8154-6930f62612bb",
   "metadata": {},
   "source": [
    "we can also iter and list folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ee70ca-2307-40c7-9201-492906a44a59",
   "metadata": {},
   "source": [
    "list(path.iterdir())\n",
    "list(path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "adf8373a-f3c4-4efe-ac92-ec13040cb5b8",
   "metadata": {},
   "source": [
    "To access paths on different storage platforms use the standard URI conventions:\n",
    "\n",
    "path = resource('scheme://\\<hostname\\>:\\<port\\>/path/to/my/file?arg1=val1&arg2=val2')\n",
    "\n",
    "Some examples:\n",
    "* s3 on AWS: s3:///\\<bucket name\\>/<\\object\\>?access_key=\\<my aws access key\\>&secret_key=\\<my secret access key\\>\n",
    "* s3 on Minio: s3://\\<hostname\\>:\\<port\\>/\\<bucket name\\>/<\\object\\>?access_key=\\<my aws access key\\>&secret_key=\\<my secret access key\\>?tls=false\n",
    "* HDFS: hdfs://\\<hostname\\>:\\<http connection port usually 9870\\>/path/to/my/file?access_key=\\<my hdfs access key\\>?tls=\\<whether connecting via https\\>\n",
    "\n",
    "\n",
    "Note that you can replace the scheme s3 with s3-pa and hdfs with hdfs-pa to get access via pyarrow which can increase performance instead of native implementations like boto3.\n",
    "For hdfs-pa you may need to replace the port to the data node communication port: usually at 50010 (consult hdfs-site.xml and core-site.xml files for details)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca253ad-79c8-4f5d-93d6-67859cebd36e",
   "metadata": {},
   "source": [
    "# Use resource to access Large Language Models (LLMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71921e7c-ca18-4971-abe5-e97dd6109d3d",
   "metadata": {},
   "source": [
    "You can use resource also to access LLMs on various platforms: openai, fastchat, tgi, internal fastapi, local huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db19b17d-7f35-4b11-bb31-cd4bccef8778",
   "metadata": {},
   "source": [
    "before accessing to the LLM, note that we can store access keys to our environment and to a local file s.t. it stays permanenty in our system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a55bd40-d314-4529-bf82-9f4d83b87dc8",
   "metadata": {},
   "source": [
    "# this would print the stored key in your system\n",
    "# beam_key['OPENAI_API_KEY']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "948a7099-4d09-46e1-ae97-26377cbe9f02",
   "metadata": {},
   "source": [
    "# this will assign a new key to your system\n",
    "# beam_key['OPENAI_API_KEY'] = 'my_key_here'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fc4bea3-4c15-4646-a0b0-b967ede02ee7",
   "metadata": {},
   "source": [
    "llm = resource('openai:///gpt-4')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2a44a816-df83-4cac-81e3-6db91cf98239",
   "metadata": {},
   "source": [
    "you can give any model instructions or chat with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f134e4a6-0cca-4b7d-9f26-69ff45dee0e0",
   "metadata": {},
   "source": [
    "llm.ask('when israel was founded? give me exact date').text"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b14c60cd-388e-480b-b5f3-3390495baf02",
   "metadata": {},
   "source": [
    "you can chat with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd392e50-1797-4fbe-a99b-229ddd32d4df",
   "metadata": {},
   "source": [
    "llm.chat('Hi my name is elad').text"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8619dd6a-0bb4-4347-bc2b-46c6729b289b",
   "metadata": {},
   "source": [
    "llm.chat('Hi again, do you remember my name?').text"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baee08f4-ec4b-46c0-a207-6b27e7e7f3e7",
   "metadata": {},
   "source": [
    "llm.chat('Hi again, do you remember my name?', reset_chat=True).text"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c4dc2886-36eb-40c4-a98f-64d23df5a1c8",
   "metadata": {},
   "source": [
    "You can also parse the response in other formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fddd02ce-d88e-451a-86b6-150fcc36cbcb",
   "metadata": {},
   "source": [
    "llm.ask('Hi how are you today? answer in a JSON format').json"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87f75131-2bbd-4122-9f88-47ae5aad1d55",
   "metadata": {},
   "source": [
    "llm.ask('Hi how are you today? answer in a YAML format').yaml"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dadc302d-7cb4-42d6-82bd-5eae9d1ec6da",
   "metadata": {},
   "source": [
    "You can use the LLM also directly with langchain without any further wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3433203-a3eb-4b10-8535-f1693e18478a",
   "metadata": {},
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c735a938-c02b-47f9-a632-2c53a7f3be30",
   "metadata": {},
   "source": [
    "llm.invoke(text)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee4df864-2f17-4422-a871-a9026e3a5ee4",
   "metadata": {},
   "source": [
    "llm.invoke(messages)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c6d5847a-405f-4f38-9eea-7429db8f8011",
   "metadata": {},
   "source": [
    "With our URIs, You can also use openai syntax with any model (not just openai), simply import our simulator instead of openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "611de8d2-19e0-4d56-92c6-15766c71506b",
   "metadata": {},
   "source": [
    "from beam.llm import openai_simulator as openai"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0719af4-00db-4a97-9aa7-5a8b2993a7bd",
   "metadata": {},
   "source": [
    "llm = resource('openai:///gpt-4')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a96fc28f-451e-4247-9e43-1122a72f4633",
   "metadata": {},
   "source": [
    "openai.Completion.create(prompt='2**10=?', model='openai:///text-davinci-003')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "06aef35a-1a58-41b1-b972-bb30094ec0c1",
   "metadata": {},
   "source": [
    "To access other LLM resource types follow the URI convention:\n",
    "\n",
    "llm = resource('scheme://\\<hostname\\>:\\<port\\>/path/to/my/file?arg1=val1&arg2=val2')\n",
    "\n",
    "possible schemes: openai, fastchat, tgi, fastapi, huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec2b48-79a9-4087-9981-73ca0c253ab5",
   "metadata": {},
   "source": [
    "# Use resource to access BeamServer algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a525b13-c700-478e-b632-c2fb15875a0b",
   "metadata": {},
   "source": [
    "You can use beam also to quickly deploy an algorithm via ssh. You can then access this algorithm with a resource object from any machine that can access the server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29700130-bab8-4f97-a3cb-c7e15092778d",
   "metadata": {},
   "source": [
    "For example, here we build a sparse similarity server (like faiss but for sparse vectors e.g. TFIDF vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "567508ce-4b29-40e2-8ace-f9b0c5dae7a1",
   "metadata": {},
   "source": [
    "from beam.sparse import SparseSimilarity\n",
    "from beam.serve import beam_server\n",
    "M = 40000"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a685a2da-716c-431e-9651-9fef4d9382da",
   "metadata": {},
   "source": [
    "sparse_sim = SparseSimilarity(metric='cosine', format='coo', vec_size=M, device='cpu', k=10)\n",
    "server = beam_server(sparse_sim, backend='waitress', non_blocking=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2652e85a-18a0-4809-8070-d2d102048b8d",
   "metadata": {},
   "source": [
    "def gen_coo_vectors(k, M, nel):\n",
    "\n",
    "    r = []\n",
    "    c = []\n",
    "    v = []\n",
    "\n",
    "    for i in range(k):\n",
    "        r.append(i * torch.ones(nel, dtype=torch.int64))\n",
    "        c.append(torch.randint(M, size=(nel,)))\n",
    "        v.append(torch.randn(nel))\n",
    "\n",
    "    return torch.sparse_coo_tensor(torch.stack([torch.cat(r), torch.cat(c)]), torch.cat(v), size=(k, M))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6365775a-69cc-42b4-8f29-d2037a34294f",
   "metadata": {},
   "source": [
    "s1 = gen_coo_vectors(20000, M, 100)\n",
    "s2 = gen_coo_vectors(20, M, 100)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7b12794-9718-416b-9b74-7802b4eabe0e",
   "metadata": {},
   "source": [
    "sparse_sim = resource('beam-http://localhost:27450')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef1bfab3-7c6c-4548-b9ed-fc49b5893755",
   "metadata": {},
   "source": [
    "sparse_sim.add(s1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a253b8f0-32ac-463b-9348-eb15ed8e65d3",
   "metadata": {},
   "source": [
    "%%time\n",
    "dist, ind = sparse_sim.search(s2, k=10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8a23abf2-8c09-4a39-9ab5-09ad1c824b1d",
   "metadata": {},
   "source": [
    "The beam server can wrap any function or class for quick and easy deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3def476-5db9-41ac-9f21-a86162f2d849",
   "metadata": {},
   "source": [
    "def llm_executor_and_store(prompt, llm='openai:///text-davinci-003?max_tokens=2048'):\n",
    "    llm = resource(llm)\n",
    "    code = llm.ask(f\"Return executable python code that performs the following task. The final result should assigned to a variable name 'res':\\n{prompt}\\n\\n\\n\").text\n",
    "    try:\n",
    "        exec(code)\n",
    "        return res, code\n",
    "    except:\n",
    "        return 'ExecutionError', code"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c01a15ea-fea7-4aea-9b70-b7333eb0c8aa",
   "metadata": {},
   "source": [
    "beam_server(llm_executor_and_store, backend='waitress', non_blocking=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5af21a34-0f9d-49ee-822d-d89615da26b0",
   "metadata": {},
   "source": [
    "remote_executor = resource('beam-http://localhost:27451')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61107d02-9615-4921-86ef-05a414c5ad21",
   "metadata": {},
   "source": [
    "r, c = remote_executor('what is the 18th number in the fibonacci series?')\n",
    "\n",
    "print(c)\n",
    "print(r)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b9bfc-69c0-4891-a8fe-d1be9209d0e6",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
