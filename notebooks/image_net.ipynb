{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae2b91c-a6fa-4c84-aafe-789be74d9312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 11:40:47.090076: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss                   # make faiss available\n",
    "import umap\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from byol_pytorch import BYOL\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "sys.path.append('..')\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from src.beam import UniversalDataset, Experiment, Algorithm, beam_arguments, PackedFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db8dbdae-5703-4459-836d-077f564e3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "        net = models.resnet50(pretrained=True, num_classes=1000)\n",
    "        # train_nodes, eval_nodes = get_graph_node_names(net)\n",
    "        return_nodes = {\n",
    "            'flatten': 'features',\n",
    "        }\n",
    "        self.net = create_feature_extractor(net, return_nodes=return_nodes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)['features'].view(len(x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6336b0db-9178-4d70-b88a-e1fb6b38c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniImageNet(UniversalDataset):\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "\n",
    "        path = hparams.path_to_data\n",
    "        seed = hparams.split_dataset_seed\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        file = os.path.join(path, 'mini_imagenet.pt')\n",
    "        if not os.path.exists(file):\n",
    "                        \n",
    "            dataset_train = [pd.read_pickle(os.path.join(path, f'train_data_batch_{i}')) for i in range(1, 11)]\n",
    "\n",
    "\n",
    "            data_train = torch.cat([torch.ByteTensor(di['data']) for di in dataset_train]).reshape(-1, 3, 64, 64)\n",
    "\n",
    "            data_train_f = data_train.float()\n",
    "\n",
    "            mu = data_train_f.mean(dim=(0, 2, 3), keepdim=True)\n",
    "            std = data_train_f.std(dim=(0, 2, 3), keepdim=True)\n",
    "\n",
    "            data_test = torch.ByteTensor(dataset_test['data']).reshape(-1, 3, 64, 64)\n",
    "\n",
    "            labels_train = torch.cat([torch.LongTensor(di['labels']) for di in dataset_train])\n",
    "            labels_test = torch.LongTensor(dataset_test['labels'])\n",
    "\n",
    "            state = {'data_train': data_train, 'data_test': data_test, \n",
    "                            'labels_train': labels_train, \n",
    "                            'labels_test': labels_test, 'mu': mu,\n",
    "                            'std': std}\n",
    "            \n",
    "            torch.save(state, file)\n",
    "        else:\n",
    "            state = torch.load(file)\n",
    "        \n",
    "        self.normalize = True\n",
    "        self.data = PackedFolds({'train': state['data_train'], 'test': state['data_test']})\n",
    "        self.labels = PackedFolds({'train': state['labels_train'], 'test': state['labels_test']})\n",
    "        self.mu = state['mu']\n",
    "        self.std = state['std']\n",
    "        self.split(validation=.2, test=self.labels['test'].index, seed=seed)\n",
    "        self.transform = torchvision.transforms.Resize((224, 224))\n",
    "\n",
    "    def getitem(self, index):\n",
    "        \n",
    "        x = self.data[index]\n",
    "        \n",
    "        if self.normalize:\n",
    "#             mu = self.mu\n",
    "#             std = self.std\n",
    "            \n",
    "#             if len(x.shape) == 3:\n",
    "#                 mu = mu.squeeze(0)\n",
    "#                 std = std.squeeze(0)\n",
    "                \n",
    "#             x = (x.float() - mu) / std\n",
    "            x = x.float() / 255\n",
    "\n",
    "            \n",
    "        x = self.transform(x)\n",
    "            \n",
    "        return {'x': x, 'y': self.labels[index]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2705d62d-90e1-40a6-8039-8246ce382580",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamBYOL(Algorithm):\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "\n",
    "        # choose your network\n",
    "        # net = FeatureNet()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "        layer = 'avgpool'\n",
    "        networks = {'learner': BYOL(resnet,\n",
    "                                   image_size = 224,\n",
    "                                   hidden_layer = layer)}\n",
    "        \n",
    "        return_nodes = {layer: 'features'}\n",
    "        \n",
    "        feature_extractor = create_feature_extractor(resnet, return_nodes=return_nodes)\n",
    "        self.features = lambda x: feature_extractor(x)['features'].view(len(x), -1)\n",
    "        \n",
    "        super().__init__(hparams, networks=networks)\n",
    "\n",
    "    \n",
    "    def preprocess_epoch(self, results=None, **kwargs):\n",
    "        \n",
    "        self.dataset.normalize = True\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def postprocess_epoch(self, results=None, training=None, **kwargs):\n",
    "        \n",
    "        print('postprocess')\n",
    "        \n",
    "        if not training:\n",
    "            \n",
    "            print('validation')\n",
    "            \n",
    "            z = np.concatenate(results['transforms']['z'])\n",
    "            y = np.concatenate(results['transforms']['y'])\n",
    "            \n",
    "            classifier = LogisticRegression(n_jobs=-1)\n",
    "            classifier.fit(z, y)\n",
    "            \n",
    "            features = self.evaluate('test', head=2000)\n",
    "            \n",
    "            z = features.values['z'].detach().cpu().numpy()\n",
    "            y = features.values['y'].detach().cpu().numpy()\n",
    "            \n",
    "            y_hat = classifier.predict(z)\n",
    "            results['scalar']['downstream'] = float(accuracy_score(y, y_pred=y_hat))\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def iteration(self, sample=None, results=None, counter=None, subset=None, training=True, **kwargs):\n",
    "\n",
    "        x, y = sample['x'], sample['y']\n",
    "\n",
    "        learner = self.networks['learner']\n",
    "        opt = self.optimizers['learner']\n",
    "\n",
    "        if training:\n",
    "            loss = learner(x)\n",
    "            opt.apply(loss, training=training)\n",
    "            learner.update_moving_average()\n",
    "\n",
    "            # add scalar measurements\n",
    "            results['scalar']['loss'].append(float(loss))\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            z = self.features(x)\n",
    "            results['transforms']['z'].append(z.detach().cpu().numpy())\n",
    "            results['transforms']['y'].append(y.detach().cpu().numpy())\n",
    "\n",
    "        return results\n",
    "    \n",
    "    def inference(self, sample=None, results=None, subset=None, predicting=True, **kwargs):\n",
    "\n",
    "        if predicting:\n",
    "            x = sample\n",
    "        else:\n",
    "            x, y = sample['x'], sample['y']\n",
    "\n",
    "        z = self.features(x)\n",
    "\n",
    "        if not predicting:\n",
    "            return {'z': z, 'y': y}, results\n",
    "\n",
    "        return z, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104041b8-175a-4511-a0f5-504c0354482e",
   "metadata": {},
   "source": [
    "## set hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add73961-8e80-45b2-a2b4-7ccb3baf270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/home/shared/data/dataset/imagenet'\n",
    "root_dir = '/home/shared/data/results'\n",
    "\n",
    "hparams = beam_arguments(\n",
    "    f\"--project-name=similarity --root-dir={root_dir} --algorithm=ImageNet --identifier=dev  --device=1 --amp\",\n",
    "    \"--epoch-length-train=50 --epoch-length-eval=20 --no-scale-epoch-by-batch-size --batch-size=128\",\n",
    "    path_to_data=path_to_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62c012d-1ef4-47b7-b6e3-1be7ad4dc772",
   "metadata": {},
   "source": [
    "## Build a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654df5ab-0803-4ca5-bd21-0135719b9d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27 s, sys: 44.8 s, total: 1min 11s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = MiniImageNet(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421eaa68-01a8-4b55-8464-5e12a62d28f6",
   "metadata": {},
   "source": [
    "### Plot image from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5d4313b-37fa-4448-a66a-ac7d2454c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.normalize = False\n",
    "\n",
    "im = np.array(dataset[10210][1]['x'].permute(1, 2, 0))\n",
    "\n",
    "plt.imshow(im)\n",
    "\n",
    "dataset.normalize = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b006a-9369-4da0-bb99-346f94277a08",
   "metadata": {},
   "source": [
    "## Build Beam Experiment with BYOL trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f6feb0e-65c7-4bf3-a057-051b4a9e7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-07-25 11:41:06\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mCreating new experiment\u001b[0m\n",
      "\u001b[32m2022-07-25 11:41:06\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mExperiment directory is: /home/shared/data/results/similarity/ImageNet/dev/0012_20220725_114106\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(hparams, print_hyperparameters=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61bc7227-9dcb-4656-8430-fea628439cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alg = experiment.algorithm_generator(BeamBYOL, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4202947b-e03c-47b3-983c-835b29ed97ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-07-25 11:41:06\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mSingle worker mode\u001b[0m\n",
      "\u001b[32m2022-07-25 11:41:06\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mWorker: 1/1 is running...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de8fc988108488984f0066579c03797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   2%|2         | 1/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocess\n",
      "postprocess\n",
      "validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1191f59e2d41148368f77e332f8334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   6%|6         | 1/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-07-25 11:43:57\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1m\u001b[0m\n",
      "\u001b[32m2022-07-25 11:43:57\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFinished epoch 1/20000 (Total trained epochs 1).\u001b[0m\n",
      "\u001b[32m2022-07-25 11:43:57\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mtrain:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:43:57\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  42.03 | batches: 50 | samples:  6.4e+03 | batch_rate:  1.19 [iter/sec] | sample_rate:  152.3 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:43:57\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mloss:        | avg: 1.905     | std: 0.3327    | min: 1.476     | 25%: 1.812     | 50%: 1.857     | 75%: 1.975     | max: 3.966     \u001b[0m\n",
      "\u001b[32m2022-07-25 11:43:57\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mvalidation:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:43:57\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  118.9 | batches: 20 | samples:  2.56e+03 | batch_rate:  5.947 [sec/iter] | sample_rate:  21.52 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:43:57\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mdownstream:  | avg: 0.02393   | std: nan       | min: 0.02393   | 25%: 0.02393   | 50%: 0.02393   | 75%: 0.02393   | max: 0.02393   \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c37331027941409c4093665fe30b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   2%|2         | 1/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocess\n",
      "postprocess\n",
      "validation\n",
      "\u001b[32m2022-07-25 11:46:15\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1m\u001b[0m\n",
      "\u001b[32m2022-07-25 11:46:15\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFinished epoch 2/20000 (Total trained epochs 2).\u001b[0m\n",
      "\u001b[32m2022-07-25 11:46:15\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mtrain:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:46:15\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  35.82 | batches: 50 | samples:  6.4e+03 | batch_rate:  1.396 [iter/sec] | sample_rate:  178.7 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:46:15\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mloss:        | avg: 1.11      | std: 0.3184    | min: 0.4448    | 25%: 0.8775    | 50%: 1.075     | 75%: 1.33      | max: 1.864     \u001b[0m\n",
      "\u001b[32m2022-07-25 11:46:15\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mvalidation:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:46:15\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  88.24 | batches: 20 | samples:  2.56e+03 | batch_rate:  4.412 [sec/iter] | sample_rate:  29.01 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:46:15\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mdownstream:  | avg: 0.01465   | std: nan       | min: 0.01465   | 25%: 0.01465   | 50%: 0.01465   | 75%: 0.01465   | max: 0.01465   \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c800a691a1429784aac2de7150436b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   4%|4         | 2/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocess\n",
      "postprocess\n",
      "validation\n",
      "\u001b[32m2022-07-25 11:48:36\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1m\u001b[0m\n",
      "\u001b[32m2022-07-25 11:48:36\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFinished epoch 3/20000 (Total trained epochs 3).\u001b[0m\n",
      "\u001b[32m2022-07-25 11:48:36\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mtrain:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:48:36\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  35.74 | batches: 50 | samples:  6.4e+03 | batch_rate:  1.399 [iter/sec] | sample_rate:  179.1 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:48:36\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mloss:        | avg: 0.8005    | std: 0.3218    | min: 0.3123    | 25%: 0.5266    | 50%: 0.7466    | 75%: 1.018     | max: 1.555     \u001b[0m\n",
      "\u001b[32m2022-07-25 11:48:36\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mvalidation:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:48:36\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  91.27 | batches: 20 | samples:  2.56e+03 | batch_rate:  4.563 [sec/iter] | sample_rate:  28.05 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:48:36\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mdownstream:  | avg: 0.02002   | std: nan       | min: 0.02002   | 25%: 0.02002   | 50%: 0.02002   | 75%: 0.02002   | max: 0.02002   \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b604db885d2c400d9c588ae12effd229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   4%|4         | 2/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocess\n",
      "postprocess\n",
      "validation\n",
      "\u001b[32m2022-07-25 11:50:54\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1m\u001b[0m\n",
      "\u001b[32m2022-07-25 11:50:54\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFinished epoch 4/20000 (Total trained epochs 4).\u001b[0m\n",
      "\u001b[32m2022-07-25 11:50:54\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mtrain:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:50:54\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  36.64 | batches: 50 | samples:  6.4e+03 | batch_rate:  1.364 [iter/sec] | sample_rate:  174.7 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:50:54\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mloss:        | avg: 0.7394    | std: 0.4062    | min: 0.3271    | 25%: 0.4669    | 50%: 0.6207    | 75%: 0.895     | max: 2.076     \u001b[0m\n",
      "\u001b[32m2022-07-25 11:50:54\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mvalidation:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:50:54\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  88.8 | batches: 20 | samples:  2.56e+03 | batch_rate:  4.44 [sec/iter] | sample_rate:  28.83 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:50:54\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mdownstream:  | avg: 0.02295   | std: nan       | min: 0.02295   | 25%: 0.02295   | 50%: 0.02295   | 75%: 0.02295   | max: 0.02295   \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ceab132a0c49b4890a78954f5d86cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   4%|4         | 2/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocess\n",
      "postprocess\n",
      "validation\n",
      "\u001b[32m2022-07-25 11:53:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1m\u001b[0m\n",
      "\u001b[32m2022-07-25 11:53:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFinished epoch 5/20000 (Total trained epochs 5).\u001b[0m\n",
      "\u001b[32m2022-07-25 11:53:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mtrain:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:53:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  36.05 | batches: 50 | samples:  6.4e+03 | batch_rate:  1.387 [iter/sec] | sample_rate:  177.6 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:53:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mloss:        | avg: 0.6892    | std: 0.4125    | min: 0.1898    | 25%: 0.4194    | 50%: 0.561     | 75%: 0.9232    | max: 2.229     \u001b[0m\n",
      "\u001b[32m2022-07-25 11:53:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mvalidation:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:53:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  87.11 | batches: 20 | samples:  2.56e+03 | batch_rate:  4.356 [sec/iter] | sample_rate:  29.39 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:53:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mdownstream:  | avg: 0.01807   | std: nan       | min: 0.01807   | 25%: 0.01807   | 50%: 0.01807   | 75%: 0.01807   | max: 0.01807   \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691bf0dda1df4d54be0384b76679394b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   4%|4         | 2/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocess\n",
      "postprocess\n",
      "validation\n",
      "\u001b[32m2022-07-25 11:55:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1m\u001b[0m\n",
      "\u001b[32m2022-07-25 11:55:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFinished epoch 6/20000 (Total trained epochs 6).\u001b[0m\n",
      "\u001b[32m2022-07-25 11:55:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mtrain:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:55:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  36.11 | batches: 50 | samples:  6.4e+03 | batch_rate:  1.385 [iter/sec] | sample_rate:  177.2 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:55:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mloss:        | avg: 0.5413    | std: 0.3264    | min: 0.09171   | 25%: 0.2888    | 50%: 0.4769    | 75%: 0.6814    | max: 1.517     \u001b[0m\n",
      "\u001b[32m2022-07-25 11:55:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mvalidation:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:55:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  72.47 | batches: 20 | samples:  2.56e+03 | batch_rate:  3.624 [sec/iter] | sample_rate:  35.32 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:55:08\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mdownstream:  | avg: 0.02246   | std: nan       | min: 0.02246   | 25%: 0.02246   | 50%: 0.02246   | 75%: 0.02246   | max: 0.02246   \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af190c9d4a84f4fb6b9d7f9e75401fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   4%|4         | 2/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocess\n",
      "postprocess\n",
      "validation\n",
      "\u001b[32m2022-07-25 11:57:19\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1m\u001b[0m\n",
      "\u001b[32m2022-07-25 11:57:19\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFinished epoch 7/20000 (Total trained epochs 7).\u001b[0m\n",
      "\u001b[32m2022-07-25 11:57:19\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mtrain:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:57:19\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  35.5 | batches: 50 | samples:  6.4e+03 | batch_rate:  1.408 [iter/sec] | sample_rate:  180.3 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:57:19\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mloss:        | avg: 0.5357    | std: 0.3424    | min: 0.1033    | 25%: 0.3003    | 50%: 0.4672    | 75%: 0.6374    | max: 1.731     \u001b[0m\n",
      "\u001b[32m2022-07-25 11:57:19\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mvalidation:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:57:19\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  84.04 | batches: 20 | samples:  2.56e+03 | batch_rate:  4.202 [sec/iter] | sample_rate:  30.46 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:57:19\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mdownstream:  | avg: 0.01807   | std: nan       | min: 0.01807   | 25%: 0.01807   | 50%: 0.01807   | 75%: 0.01807   | max: 0.01807   \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad27fa611854724baabf8c2a5b25ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   4%|4         | 2/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocess\n",
      "postprocess\n",
      "validation\n",
      "\u001b[32m2022-07-25 11:59:16\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1m\u001b[0m\n",
      "\u001b[32m2022-07-25 11:59:16\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFinished epoch 8/20000 (Total trained epochs 8).\u001b[0m\n",
      "\u001b[32m2022-07-25 11:59:16\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mtrain:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:59:16\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  34.41 | batches: 50 | samples:  6.4e+03 | batch_rate:  1.453 [iter/sec] | sample_rate:  186.0 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:59:16\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mloss:        | avg: 0.539     | std: 0.3224    | min: 0.1402    | 25%: 0.3297    | 50%: 0.4297    | 75%: 0.6866    | max: 1.506     \u001b[0m\n",
      "\u001b[32m2022-07-25 11:59:16\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mvalidation:\u001b[0m\n",
      "\u001b[32m2022-07-25 11:59:16\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  72.0 | batches: 20 | samples:  2.56e+03 | batch_rate:  3.6 [sec/iter] | sample_rate:  35.56 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 11:59:16\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mdownstream:  | avg: 0.01709   | std: nan       | min: 0.01709   | 25%: 0.01709   | 50%: 0.01709   | 75%: 0.01709   | max: 0.01709   \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2551d2a9f4ec4c50a540cdbbe9bea444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   4%|4         | 2/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocess\n",
      "postprocess\n",
      "validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-07-25 12:01:27\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1m\u001b[0m\n",
      "\u001b[32m2022-07-25 12:01:27\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFinished epoch 9/20000 (Total trained epochs 9).\u001b[0m\n",
      "\u001b[32m2022-07-25 12:01:27\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mtrain:\u001b[0m\n",
      "\u001b[32m2022-07-25 12:01:27\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  35.7 | batches: 50 | samples:  6.4e+03 | batch_rate:  1.4 [iter/sec] | sample_rate:  179.2 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 12:01:27\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mloss:        | avg: 0.5778    | std: 0.372     | min: 0.09351   | 25%: 0.2877    | 50%: 0.4996    | 75%: 0.7337    | max: 1.912     \u001b[0m\n",
      "\u001b[32m2022-07-25 12:01:27\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mvalidation:\u001b[0m\n",
      "\u001b[32m2022-07-25 12:01:27\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  84.17 | batches: 20 | samples:  2.56e+03 | batch_rate:  4.209 [sec/iter] | sample_rate:  30.41 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 12:01:27\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mdownstream:  | avg: 0.02051   | std: nan       | min: 0.02051   | 25%: 0.02051   | 50%: 0.02051   | 75%: 0.02051   | max: 0.02051   \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c7cea517414e1ca1a2d32cf52886f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   2%|2         | 1/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocess\n",
      "validation\n",
      "\u001b[32m2022-07-25 12:03:31\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1m\u001b[0m\n",
      "\u001b[32m2022-07-25 12:03:31\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFinished epoch 10/20000 (Total trained epochs 10).\u001b[0m\n",
      "\u001b[32m2022-07-25 12:03:31\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mtrain:\u001b[0m\n",
      "\u001b[32m2022-07-25 12:03:31\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  35.19 | batches: 50 | samples:  6.4e+03 | batch_rate:  1.421 [iter/sec] | sample_rate:  181.9 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 12:03:31\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mloss:        | avg: 0.5203    | std: 0.2832    | min: 0.1445    | 25%: 0.2973    | 50%: 0.4354    | 75%: 0.7378    | max: 1.282     \u001b[0m\n",
      "\u001b[32m2022-07-25 12:03:31\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mvalidation:\u001b[0m\n",
      "\u001b[32m2022-07-25 12:03:31\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  75.29 | batches: 20 | samples:  2.56e+03 | batch_rate:  3.764 [sec/iter] | sample_rate:  34.0 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 12:03:31\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mdownstream:  | avg: 0.02783   | std: nan       | min: 0.02783   | 25%: 0.02783   | 50%: 0.02783   | 75%: 0.02783   | max: 0.02783   \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f71857a7ff84917a7daec522aa5f82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   4%|4         | 2/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocess\n",
      "postprocess\n",
      "validation\n",
      "\u001b[32m2022-07-25 12:05:34\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1m\u001b[0m\n",
      "\u001b[32m2022-07-25 12:05:34\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFinished epoch 11/20000 (Total trained epochs 11).\u001b[0m\n",
      "\u001b[32m2022-07-25 12:05:34\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mtrain:\u001b[0m\n",
      "\u001b[32m2022-07-25 12:05:34\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  35.77 | batches: 50 | samples:  6.4e+03 | batch_rate:  1.398 [iter/sec] | sample_rate:  178.9 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 12:05:34\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mloss:        | avg: 0.474     | std: 0.2952    | min: 0.06605   | 25%: 0.2799    | 50%: 0.4216    | 75%: 0.6041    | max: 1.404     \u001b[0m\n",
      "\u001b[32m2022-07-25 12:05:34\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mvalidation:\u001b[0m\n",
      "\u001b[32m2022-07-25 12:05:34\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mseconds:  75.6 | batches: 20 | samples:  2.56e+03 | batch_rate:  3.78 [sec/iter] | sample_rate:  33.86 [iter/sec] \u001b[0m\n",
      "\u001b[32m2022-07-25 12:05:34\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mdownstream:  | avg: 0.02441   | std: nan       | min: 0.02441   | 25%: 0.02441   | 50%: 0.02441   | 75%: 0.02441   | max: 0.02441   \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adacff8bd45483683a6bdaa39a77076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   4%|4         | 2/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-07-25 12:05:50\u001b[0m | \u001b[31m\u001b[1mERROR\u001b[0m | \u001b[31m\u001b[1mKeyboardInterrupt: Training was interrupted, Worker terminates\u001b[0m\n",
      "\u001b[32m2022-07-25 12:05:50\u001b[0m | \u001b[31m\u001b[1mERROR\u001b[0m | \u001b[31m\u001b[1mKeyboardInterrupt: Training was interrupted, reloads last checkpoint\u001b[0m\n",
      "\u001b[32m2022-07-25 12:05:50\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mReload experiment from checkpoint: /home/shared/data/results/similarity/ImageNet/dev/0012_20220725_114106/checkpoints/checkpoint_000011\u001b[0m\n",
      "\u001b[32m2022-07-25 12:05:50\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mLoading network state from: /home/shared/data/results/similarity/ImageNet/dev/0012_20220725_114106/checkpoints/checkpoint_000011\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "alg = experiment.fit(BeamBYOL, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f01f332a-e558-4bf0-8912-94f1f0fecf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0579bec8e64e43b1cd713e72347a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 1/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = alg.evaluate('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ccd8ced-6694-41ff-ac6a-7d4099baa935",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = alg.evaluate('test', max_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11f8b501-b014-4e06-a199-16887a7b6368",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = features.values['z'].detach().cpu().numpy()\n",
    "y = features.values['y'].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216a150-a2f0-4afd-b54c-a6279071f79a",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9c9c2d1-b507-4c5f-bfa5-84dc1653f121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e6823d6-48ba-4a1c-ad7e-e27edfaa6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ff73347-e915-4fd7-aee1-7aff8bd6a8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 53s, sys: 6min 34s, total: 8min 27s\n",
      "Wall time: 14.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b402babc-57a7-4feb-99e1-f6c254a4434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clf.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b840ceed-213a-43b4-8009-5987c8573688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "161e003a-3550-4c35-af82-eb54d2c23252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79421875"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_pred=y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00759bef-a388-4c9f-9064-11097837e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = RandomForestClassifier(min_samples_leaf=20)\n",
    "# clf.fit(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ea736-001f-48de-ae52-9e07d2afd02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = svm.LinearSVC()\n",
    "\n",
    "# clf.fit(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa8ba7-c29d-4ced-879c-8a76b30453fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b83d620f-86a5-44ab-bfbe-7065e95773e7",
   "metadata": {},
   "source": [
    "## Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d00b3b9-cbad-4b47-9e8b-8e1904345824",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = z.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "23630b38-1865-4ff5-b998-005b799479c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = faiss.IndexFlatL2(d)   # build the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3724aed-ffbd-43f4-8968-f14c067c6588",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = faiss.StandardGpuResources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d5b28dcc-e81e-4d94-9f2e-4f5876f94d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a flat (CPU) index\n",
    "index_flat = faiss.IndexFlatL2(d)\n",
    "# make it into a gpu index\n",
    "gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b6a22d5e-98e5-49c4-bc71-fe4001105b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "gpu_index_flat.add(z)         # add vectors to the index\n",
    "print(gpu_index_flat.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b55f1c42-5a26-4aac-b8a6-8cec3ec3e91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_flat.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a8800a4-302e-464a-a9df-71af3b137bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 4                          # we want to see 4 nearest neighbors\n",
    "# D, I = gpu_index_flat.search(z[:5], k)  # actual search\n",
    "\n",
    "# %%time\n",
    "\n",
    "# # we want to see 4 nearest neighbors\n",
    "# D, I = gpu_index_flat.search(z, k) # sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4409a518-ac18-4fe3-b9dc-89f9aeba20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1000\n",
    "\n",
    "y = features.data['y']\n",
    "\n",
    "D, I = gpu_index_flat.search(z[[i]], 100) # sanity check\n",
    "\n",
    "len(np.unique(y[I[0]]))\n",
    "\n",
    "zvi = z[I[0]]\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "\n",
    "embedding = reducer.fit_transform(zvi)\n",
    "\n",
    "plt.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    c=y[I[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84458852-497f-48f5-ab3c-c47e18c9c08c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/faiss/__init__.py:322\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_search\u001b[0;34m(self, x, k, D, I)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m I\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (n, k)\n\u001b[0;32m--> 322\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswig_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswig_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswig_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m D, I\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/faiss/swigfaiss.py:2146\u001b[0m, in \u001b[0;36mIndexFlat.search\u001b[0;34m(self, n, x, k, distances, labels)\u001b[0m\n\u001b[1;32m   2145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m, n, x, k, distances, labels):\n\u001b[0;32m-> 2146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_swigfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexFlat_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# we want to see 4 nearest neighbors\n",
    "D, I = index.search(z, k) # sanity check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
