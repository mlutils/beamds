{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee9ffa7d-e034-4f44-b5a7-60c8b0451cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the Beam environment for interactive use\n",
      "Standard modules will be automatically imported so you can use them without explicit import\n",
      "Done importing packages. It took:  4.1 seconds\n",
      "Beam library is loaded from path: /home/elad/docker/beamds/src/beam\n",
      "The Beam version is: 2.4.6b\n"
     ]
    }
   ],
   "source": [
    "%load_ext beam_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a63003f3-7893-4ae6-bc5a-d5eec495fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beam.similarity import TFIDF, SparnnSimilarity, DenseSimilarity\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import AutoTokenizer\n",
    "from beam import beam_logger as logger\n",
    "from beam.utils import Timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d4988b-c042-4e63-9612-d89afd8e67e6",
   "metadata": {},
   "source": [
    "# Tokenize the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f50aeb14-00ff-4384-8c34-9846f32e370d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-26 15:00:36\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mLoaded dataset: newsgroups_train\u001b[0m\n",
      "\u001b[32m2024-02-26 15:00:36\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mLoaded tokenizer: mistralai/Mistral-7B-v0.1\u001b[0m\n",
      "\u001b[32m2024-02-26 15:00:37\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mTokenizing data: newsgroups_train\u001b[0m\n",
      "\u001b[32m2024-02-26 15:00:39\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mTokenizing data: newsgroups_test\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load the 20 newsgroups dataset\n",
    "\n",
    "logger.info(f\"Loaded dataset: newsgroups_train\")\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "tokenizer_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "logger.info(f\"Loaded tokenizer: {tokenizer_name}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "logger.info(f\"Tokenizing data: newsgroups_train\")\n",
    "x = tokenizer(newsgroups_train.data, add_special_tokens=False)[\"input_ids\"]\n",
    "\n",
    "logger.info(f\"Tokenizing data: newsgroups_test\")\n",
    "q = tokenizer(newsgroups_test.data, add_special_tokens=False)[\"input_ids\"]\n",
    "index = newsgroups_train['filenames']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e3ad2-c408-4a70-8e22-072dcbbc34b7",
   "metadata": {},
   "source": [
    "## Apply TFIDFVectorizer (SKlearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf0527de-f983-4454-9a87-8e177ff34541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-26 15:00:42\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting timer: TfidfVectorizer.fit_transform\u001b[0m\n",
      "\u001b[32m2024-02-26 15:00:46\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mTransformed data: (11314, 23459)\u001b[0m\n",
      "\u001b[32m2024-02-26 15:00:46\u001b[0m | BeamLog | \u001b[41m\u001b[1mCRITICAL\u001b[0m | \u001b[41m\u001b[1m1x2: 0.229594450049725\u001b[0m\n",
      "\u001b[32m2024-02-26 15:00:46\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mTimer TfidfVectorizer.fit_transform paused. Elapsed time: 4.6792     Sec\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "x_str = [' '.join([str(i) for i in xi]) for xi in x]\n",
    "\n",
    "with Timer(name='TfidfVectorizer.fit_transform', logger=logger) as t:\n",
    "    tfidf = TfidfVectorizer()\n",
    "    vectors = tfidf.fit_transform(x_str)\n",
    "\n",
    "    logger.info(f\"Transformed data: {vectors.shape}\")\n",
    "    logger.critical(f\"1x2: {(vectors[0].toarray() * vectors[1].toarray()).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c49fe-7ee3-4dc3-aa10-fe41af80760e",
   "metadata": {},
   "source": [
    "## Apply Beam's TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "243589e9-0101-4b25-82dc-d0c60bc90855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-26 15:27:59\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting timer: BeamTFIDF.fit_transform\u001b[0m\n",
      "\u001b[32m2024-02-26 15:27:59\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting transformer process: self\u001b[0m\n",
      "\u001b[32m2024-02-26 15:27:59\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mSplitting data to chunks for transformer: self\u001b[0m\n",
      "\u001b[32m2024-02-26 15:27:59\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting transformer: self with 1 workers. Number of queued tasks is 1.\u001b[0m\n",
      "\u001b[32m2024-02-26 15:27:59\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting task: 0 (self)\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:01\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinished task: 0 (self). Elapsed time: 2.813175678253174\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:01\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mRunning queue (length=1) on the main thread: self with 1 worker\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:01\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinish running queue: self.\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:01\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinished transformer process: self. Collating results...\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:03\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting transformer process: self\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:03\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mSplitting data to chunks for transformer: self\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:03\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting transformer: self with 1 workers. Number of queued tasks is 1.\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:03\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting task: 0 (self)\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinished task: 0 (self). Elapsed time: 5.019611120223999\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mRunning queue (length=1) on the main thread: self with 1 worker\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinish running queue: self.\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinished transformer process: self. Collating results...\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mTransformed data: torch.Size([11314, 31151])\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[41m\u001b[1mCRITICAL\u001b[0m | \u001b[41m\u001b[1m1x2: 0.22957365214824677\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mTimer BeamTFIDF.fit_transform paused. Elapsed time: 9.4671     Sec\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with Timer(name='BeamTFIDF.fit_transform', logger=logger) as t:\n",
    "    # Create a TFIDF model\n",
    "    tfidf = TFIDF(sparse_framework='torch', device=0, n_workers=1)\n",
    "\n",
    "    # Fit the model\n",
    "    vectors = tfidf.fit_transform(x, index)\n",
    "\n",
    "    logger.info(f\"Transformed data: {vectors.shape}\")\n",
    "\n",
    "    try:\n",
    "        logger.critical(f\"1x2: {(vectors[0].to_dense() * vectors[1].to_dense()).sum()}\")\n",
    "    except AttributeError:\n",
    "        logger.critical(f\"1x2: {(vectors[0].toarray() * vectors[1].toarray()).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d1156fb-e298-4235-871b-3c587280e636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting transformer process: self\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mSplitting data to chunks for transformer: self\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting transformer: self with 1 workers. Number of queued tasks is 1.\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting task: 0 (self)\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinished task: 0 (self). Elapsed time: 0.00810098648071289\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mRunning queue (length=1) on the main thread: self with 1 worker\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinish running queue: self.\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinished transformer process: self. Collating results...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sim = tfidf.search(q[:10], k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30e0fa73-6d2f-4321-a181-a6f6cf9ad07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Similarities(index=array([['/root/scikit_learn_data/20news_home/20news-bydate-train/sci.electronics/53691',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/sci.electronics/53894'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/sci.crypt/15605',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/talk.politics.misc/176993'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/51241',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/51240'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/51319',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/53323'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/51179',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/51181'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/sci.med/59165',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/sci.med/59183'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/soc.religion.christian/20746',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/soc.religion.christian/20661'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/comp.sys.ibm.pc.hardware/58926',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/comp.os.ms-windows.misc/9734'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/comp.windows.x/66991',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/comp.windows.x/67022'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38631',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38366']],\n",
       "      dtype='<U86'), distance=tensor([[ 547.8058,  527.4254],\n",
       "        [ 816.0970,  638.8770],\n",
       "        [ 384.2907,  377.1268],\n",
       "        [2650.8264, 2631.9836],\n",
       "        [1051.9596, 1031.1426],\n",
       "        [3598.1558, 3420.2913],\n",
       "        [ 194.2403,  185.7745],\n",
       "        [ 424.1982,  423.3763],\n",
       "        [ 326.3408,  324.0290],\n",
       "        [ 632.3304,  624.7346]], device='cuda:0'), values=None, sparse_scores=None, metric='bm25', model='tfidf')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12aa689-4d58-451a-b0e6-00ea31033f50",
   "metadata": {},
   "source": [
    "## Caculate BM25 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3d4f3be-510b-4276-ba74-82b852113282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting timer: BeamTFIDF.bm25\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting transformer process: self\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mSplitting data to chunks for transformer: self\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting transformer: self with 1 workers. Number of queued tasks is 1.\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:08\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting task: 0 (self)\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:12\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinished task: 0 (self). Elapsed time: 3.3209149837493896\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:12\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mRunning queue (length=1) on the main thread: self with 1 worker\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:12\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinish running queue: self.\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:12\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinished transformer process: self. Collating results...\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:12\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mTimer BeamTFIDF.bm25 paused. Elapsed time: 3.3477     Sec\u001b[0m\n",
      "tensor([[360.2389, 372.9930, 408.1216,  ..., 341.8739, 365.6027, 332.9762],\n",
      "        [480.1192, 468.7175, 517.4191,  ..., 434.7433, 526.3921, 465.5964],\n",
      "        [224.8805, 230.8067, 241.4396,  ..., 232.7298, 272.3540, 210.9205],\n",
      "        ...,\n",
      "        [647.2286, 643.1620, 706.9319,  ..., 578.2476, 749.4446, 564.7783],\n",
      "        [569.9807, 614.0554, 772.1633,  ..., 633.5697, 652.2048, 741.0157],\n",
      "        [482.0046, 509.0900, 585.7748,  ..., 441.6497, 602.0982, 459.1748]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with Timer(name='BeamTFIDF.bm25', logger=logger) as t:\n",
    "    # Transform the test data\n",
    "    scores = tfidf.bm25(q)\n",
    "\n",
    "# Print the shape of the transformed data\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20807974-b3d2-4e99-b99f-1b615d9b1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparnn = SparnnSimilarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "effd9899-7fdc-4984-b160-ab3c105c748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparnn.add(vectors, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2016ce5-b20c-4271-bd12-1715a3d53e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-26 15:28:42\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting transformer process: self\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:43\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mSplitting data to chunks for transformer: self\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:43\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting transformer: self with 1 workers. Number of queued tasks is 1.\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:43\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mStarting task: 0 (self)\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:43\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinished task: 0 (self). Elapsed time: 0.011901617050170898\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:43\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mRunning queue (length=1) on the main thread: self with 1 worker\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:43\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinish running queue: self.\u001b[0m\n",
      "\u001b[32m2024-02-26 15:28:43\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mFinished transformer process: self. Collating results...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "vq = tfidf.transform(q[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a3f8904-7639-4800-9d89-d37533e715e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Similarities(index=array([['/root/scikit_learn_data/20news_home/20news-bydate-train/sci.electronics/53894',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/talk.religion.misc/84165'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/sci.crypt/15605',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38377'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/53380',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/51240'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/talk.politics.guns/54229',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/52499'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/51179',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/51191'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/sci.med/59183',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/sci.med/59165'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/soc.religion.christian/21316',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/soc.religion.christian/20661'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38376',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/comp.sys.ibm.pc.hardware/58926'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/comp.windows.x/67005',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/rec.autos/101656'],\n",
       "       ['/root/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38666',\n",
       "        '/root/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38745']],\n",
       "      dtype='<U86'), distance=array([[0.46450531, 0.49018449],\n",
       "       [0.54161668, 0.61469555],\n",
       "       [0.48110056, 0.51289266],\n",
       "       [0.42538702, 0.43441075],\n",
       "       [0.37448341, 0.41334015],\n",
       "       [0.36165684, 0.3646729 ],\n",
       "       [0.4842028 , 0.55948365],\n",
       "       [0.67204541, 0.67892873],\n",
       "       [0.646891  , 0.64760655],\n",
       "       [0.53972018, 0.5482657 ]]), values=None, sparse_scores=None, metric='cosine', model='sparnn')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparnn.search(vq, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a9a09a-edf2-4858-a759-20822d895e78",
   "metadata": {},
   "source": [
    "# Apply beam dense similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6eca5b4d-4c5e-4c05-99d6-b1eb5e6fd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa436880-e8d9-4a0f-9a72-a42f32faebd8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-21:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-27:\n",
      "Process ForkProcess-23:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-30:\n",
      "Process ForkProcess-17:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-26:\n",
      "Process ForkProcess-24:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-32:\n",
      "Process ForkProcess-22:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-29:\n",
      "Process ForkProcess-28:\n",
      "Process ForkProcess-2:\n",
      "Process ForkProcess-25:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-16:\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-31:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "device = beam_device(0)\n",
    "dense_model = SentenceTransformer('BAAI/bge-base-en-v1.5', device=str(device))\n",
    "d = dense_model.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53345e90-2d8e-40cd-8227-5a50dfd641de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d38dc163ba2438082ae212fb6d3f564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/354 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xd = dense_model.encode(newsgroups_train.data, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181c496-d5a0-4458-ade5-8a0eb04d3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qd = dense_model.encode(newsgroups_test.data, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8cb7e2ed-da99-4310-9047-bc36270844bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-26 15:34:45\u001b[0m | BeamLog | \u001b[1mINFO\u001b[0m | \u001b[1mUsing HNSW64. Expected RAM footprint is 40.549     MB\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dense_sim = DenseSimilarity(d=d, expected_population=len(x),\n",
    "                 metric='cosine', training_device='cpu', inference_device='cpu', ram_footprint=2**8*int(1e9),\n",
    "                 gpu_footprint=24*int(1e9), exact=False, nlists=None, faiss_M=None,\n",
    "                 reducer='umap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "265e1b72-2a24-4a13-b426-77c17043598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_sim.add(xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d182ba76-e512-4015-8b0b-cde0f0528ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = dense_sim.search(qd[:10], k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22dfd161-0c1d-4fb0-95f8-fede6a7731f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Similarities(index=array([[ 3123, 30165],\n",
       "       [ 3123, 30165],\n",
       "       [ 3123, 30165],\n",
       "       [ 3123, 30165],\n",
       "       [ 3123, 30165],\n",
       "       [ 3123, 30165],\n",
       "       [ 3123, 30165],\n",
       "       [ 3123, 30165],\n",
       "       [ 3123, 30165],\n",
       "       [ 3123, 30165]]), distance=array([[1.0000006, 1.0000006],\n",
       "       [1.0000006, 1.0000006],\n",
       "       [1.0000006, 1.0000006],\n",
       "       [1.0000006, 1.0000006],\n",
       "       [1.0000006, 1.0000006],\n",
       "       [1.0000006, 1.0000006],\n",
       "       [1.0000006, 1.0000006],\n",
       "       [1.0000006, 1.0000006],\n",
       "       [1.0000006, 1.0000006],\n",
       "       [1.0000006, 1.0000006]], dtype=float32), values=None, sparse_scores=None, metric='cosine', model='faiss')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b3653a-0b89-40aa-b07d-ae2fea3aa46a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
